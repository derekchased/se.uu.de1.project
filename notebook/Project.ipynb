{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4b385e1-5065-4145-85e3-1d664c330cc3",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e33c383-6cfe-4d3b-b460-74c48841ffb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "2022-03-14 11:53:08,330 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2022-03-14 11:53:08,630 WARN util.Utils: Service 'sparkDriver' could not bind on port 9998. Attempting port 9999.\n",
      "2022-03-14 11:53:08,864 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "2022-03-14 11:53:09,174 WARN util.Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on port 10005. Attempting port 10006.\n",
      "2022-03-14 11:53:09,269 WARN spark.ExecutorAllocationManager: Dynamic allocation without a shuffle service is an experimental feature.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from operator import add\n",
    "\n",
    "import json\n",
    "\n",
    "spark_session = SparkSession\\\n",
    "        .builder\\\n",
    "        .master(\"spark://de1:7077\") \\\n",
    "        .appName(\"simon_pettersson_de1_p\")\\\n",
    "        .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    "        .config(\"spark.dynamicAllocation.shuffleTracking.enabled\",True)\\\n",
    "        .config(\"spark.shuffle.service.enabled\", False)\\\n",
    "        .config(\"spark.dynamicAllocation.executorIdleTimeout\",\"30s\")\\\n",
    "        .config(\"spark.executor.cores\",2)\\\n",
    "        .config(\"spark.driver.port\",9998)\\\n",
    "        .config(\"spark.blockManager.port\",10005)\\\n",
    "        .getOrCreate()\n",
    "\n",
    "# Old API (RDD)\n",
    "spark_context = spark_session.sparkContext\n",
    "\n",
    "spark_context.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5f291bb-e194-405f-9207-f5f7d3ef6c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "posts = spark_context.textFile(\"hdfs://127.0.0.1:9000/RC_2005-12.bz2\").map(lambda x: json.loads(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc95d6dd-032f-425c-ac5f-b18a62a1b0ce",
   "metadata": {},
   "source": [
    "### Print a sample from the loaded JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71bc3f74-5e00-410b-a869-85b08694d791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample JSON entry from read file:\n",
      "[{'controversiality': 0, 'body': 'A look at Vietnam and Mexico exposes the myth of market liberalisation.', 'subreddit_id': 't5_6', 'link_id': 't3_17863', 'stickied': False, 'subreddit': 'reddit.com', 'score': 2, 'ups': 2, 'author_flair_css_class': None, 'created_utc': 1134365188, 'author_flair_text': None, 'author': 'frjo', 'id': 'c13', 'edited': False, 'parent_id': 't3_17863', 'gilded': 0, 'distinguished': None, 'retrieved_on': 1473738411}]\n"
     ]
    }
   ],
   "source": [
    "print('Sample JSON entry from read file:')\n",
    "print(str(posts.take(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ed50b1-e7ec-4b14-80f5-a8287e9341a9",
   "metadata": {},
   "source": [
    "### Define functions used to map posts to lists of words and controversiality scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a83484c6-218e-428b-80d7-daf899e3fc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_words(post):\n",
    "    content = post.get('body')\n",
    "    \n",
    "    if content is None:\n",
    "        return None\n",
    "    \n",
    "    return [ re.sub(r'[^a-zA-Z0-9]', '', word).lower() for word in content.split(\" \") ]\n",
    "\n",
    "def get_words_controversiality(post):\n",
    "    words = get_words(post)\n",
    "    controversiality = post.get('controversiality')\n",
    "    \n",
    "    if words is None or controversiality is None:\n",
    "        return None\n",
    "    \n",
    "    return [ (word, controversiality) for word in words ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c020b98f-6563-48ab-8d41-4a378315b1a1",
   "metadata": {},
   "source": [
    "### Map posts to its words along with the controversiality of the post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43a519cf-e6d0-44c5-8ef5-459004a1d98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = posts.flatMap(lambda post: get_words_controversiality(post)).filter(lambda entry: entry is not None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458fb122-45f8-48b1-a1e0-2babfcaadd75",
   "metadata": {},
   "source": [
    "### Append a count to each word specifying its number of occurances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ade13ad-4c55-4b0b-becd-5e0c97a17059",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_with_counts = words.map(lambda entry: (entry[0], (entry[1], 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b5427c-eeb2-475c-ac9a-32847cbeade3",
   "metadata": {},
   "source": [
    "### Reduce words to combine their controversiality and count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "901bb6e5-1b4e-4c36-a800-571d977d61ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced = words_with_counts.reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1])) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668f22c3-6aea-47b6-b06c-fe02a9371039",
   "metadata": {},
   "source": [
    "### Remove words occuring less than N times, to filter out words with insufficient data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c9eb474-9829-41fb-ae65-56a77fb8127d",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_occurances = 100\n",
    "filtered_words = reduced.filter(lambda word: word[1][1] >= min_occurances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ee02f2-dc70-49d8-a4b0-c2c19b76dec2",
   "metadata": {},
   "source": [
    "### Calculate percentage of how many of the words that occur in a controversial post, and sort them in descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12337c6f-8c00-4744-9e90-0d8f0fba576f",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_percentages = filtered_words\\\n",
    "    .map(lambda word: (word[0], word[1][0] / word[1][1]))\\\n",
    "    .sortBy(lambda word: word[1], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386cd237-a8ca-4339-adee-225bb1f4a4a5",
   "metadata": {},
   "source": [
    "### Print the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e66d216-ea67-4f75-a84c-b710a5ca2f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing top 100 most controversial words\n",
      "because: 12.0%   \n",
      "    his: 11.21%  \n",
      "     he: 9.46%   \n",
      "    who: 9.24%   \n",
      "     im: 9.02%   \n",
      "   some: 8.97%   \n",
      "     me: 8.45%   \n",
      " people: 8.24%   \n",
      " really: 7.96%   \n",
      "   only: 7.84%   \n",
      "    was: 7.76%   \n",
      "    how: 7.56%   \n",
      "   like: 7.37%   \n",
      "      i: 7.24%   \n",
      "    are: 7.23%   \n",
      "  about: 7.17%   \n",
      "   know: 6.8%    \n",
      "   what: 6.31%   \n",
      "  which: 6.19%   \n",
      "  think: 6.15%   \n",
      "    you: 6.05%   \n",
      "     is: 5.82%   \n",
      "   just: 5.78%   \n",
      "deleted: 5.56%   \n",
      "  their: 5.51%   \n",
      "     do: 5.46%   \n",
      "   with: 5.42%   \n",
      "   this: 5.36%   \n",
      "    not: 5.35%   \n",
      "       : 5.31%   \n",
      "     to: 5.2%    \n",
      "  would: 5.16%   \n",
      "     on: 5.05%   \n",
      "    but: 5.03%   \n",
      "article: 4.9%    \n",
      "   that: 4.81%   \n",
      "  there: 4.8%    \n",
      "    can: 4.73%   \n",
      "     my: 4.73%   \n",
      "     it: 4.72%   \n",
      "    its: 4.66%   \n",
      "   they: 4.65%   \n",
      "      a: 4.6%    \n",
      "     at: 4.59%   \n",
      "     no: 4.59%   \n",
      "    one: 4.58%   \n",
      "   good: 4.55%   \n",
      "     so: 4.5%    \n",
      "     an: 4.42%   \n",
      "    and: 4.29%   \n",
      "     of: 4.24%   \n",
      "     in: 4.18%   \n",
      "    the: 4.17%   \n",
      "   dont: 4.14%   \n",
      "   than: 3.97%   \n",
      "     up: 3.92%   \n",
      "    all: 3.9%    \n",
      "     by: 3.9%    \n",
      "     as: 3.86%   \n",
      "     be: 3.69%   \n",
      "    for: 3.55%   \n",
      "   have: 3.49%   \n",
      "    has: 3.25%   \n",
      "     or: 3.09%   \n",
      "     if: 2.87%   \n",
      "   from: 2.61%   \n",
      "   your: 2.52%   \n",
      "   more: 2.22%   \n",
      "    out: 1.68%   \n"
     ]
    }
   ],
   "source": [
    "# Number of words to print\n",
    "num = 100\n",
    "print(f'Printing top {num} most controversial words')\n",
    "\n",
    "# Get subset of length num from start of sorted word list\n",
    "top_words = word_percentages.take(num)\n",
    "\n",
    "# Find the length of the longest word to make formatting prettier\n",
    "max_length = max([ len(word[0]) for word in top_words ])\n",
    "\n",
    "# Define a format for printing words, where words are left-padded with spaces \n",
    "# to become max_length long\n",
    "print_format = '{:>' + str(max_length) + '}: {:<8}'\n",
    "\n",
    "# Iterate over all top words and print them\n",
    "for entry in top_words:\n",
    "    # Find the word from the tuple\n",
    "    word = entry[0]\n",
    "    \n",
    "    # Multiply by 100 and round to two decimal points\n",
    "    percentage = round(entry[1]*100, 2)\n",
    "    \n",
    "    # Print the word and percentage using the previously defined format\n",
    "    print(print_format.format(\\\n",
    "                entry[0], \\\n",
    "                str(percentage) + '%'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
